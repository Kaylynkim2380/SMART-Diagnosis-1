# -*- coding: utf-8 -*-
"""smart diagnosis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bHtTp8Z08E8s9RdhhPVtqR-E6lcVr5j8
"""

import subprocess
import sys

def install_package(package):
    subprocess.check_call([sys.executable, "-m", "pip", "install", package])

# Install required packages
install_package("tensorflow")
install_package("tensorflow-io")
install_package("soundfile")
install_package("pydub")

# Replace !apt-get with Python equivalent
try:
    subprocess.check_call(["apt-get", "install", "-y", "ffmpeg"])
except:
    print("Note: ffmpeg installation may require sudo privileges")

import os #Allows for easy navigation within file directories
from matplotlib import pyplot as plt #For data visualizations
import tensorflow as tf #To build the deep learning model
import tensorflow_io as tfio #Efficient processing of audio clips
import librosa
import numpy as np  # Import numpy
import glob  # For listing audio files

from google.colab import drive
drive.mount('/content/drive')

print(os.listdir('/content/drive/MyDrive/training_set'))

COPD_FOLDER = '/content/drive/MyDrive/training_set/COPD/'
NOT_COPD_FOLDER = '/content/drive/MyDrive/training_set/NOT_COPD/'

# Check if the paths exist
print("COPD folder exists:", os.path.exists(COPD_FOLDER))
print("NOT COPD folder exists:", os.path.exists(NOT_COPD_FOLDER))

# List all files in each folder
COPD_files = [os.path.join(COPD_FOLDER, f) for f in os.listdir(COPD_FOLDER) if f.endswith('.wav')]
NOT_COPD_files = [os.path.join(NOT_COPD_FOLDER, f) for f in os.listdir(NOT_COPD_FOLDER) if f.endswith('.wav')]

print("COPD Files:", COPD_files)
print("Non-COPD Files:", NOT_COPD_files)

fixed_length = 80000  # 5 seconds at 16 kHz
def load_and_pad_audio(file_path):
    # Load audio file using librosa with a sample rate of 16 kHz
    audio, _ = librosa.load(file_path, sr=16000)
    # Pad or truncate to 80,000 samples (5 seconds)
    if len(audio) < fixed_length:
        audio = np.pad(audio, (0, fixed_length - len(audio)), 'constant')
    else:
        audio = audio[:fixed_length]
    return audio

def load_and_pad_audio(file_path):
    audio, _ = librosa.load(file_path, sr=16000)
    if len(audio) < fixed_length:
        audio = np.pad(audio, (0, fixed_length - len(audio)), 'constant')
    else:
        audio = audio[:fixed_length]
    return audio

copd_data = [load_and_pad_audio(file) for file in COPD_files]
non_copd_data = [load_and_pad_audio(file) for file in NOT_COPD_files]

copd_data = [load_and_pad_audio(file) for file in COPD_files]
non_copd_data = [load_and_pad_audio(file) for file in NOT_COPD_files]

# Check if all data is the same length
print("Shape of first COPD audio:", np.array(copd_data[0]).shape)
print("Shape of first Non-COPD audio:", np.array(non_copd_data[0]).shape)

# Define labels for the two categories
copd_labels = [1] * len(copd_data)
non_copd_labels = [0] * len(non_copd_data)

# Stack data and labels together
data = np.array(copd_data + non_copd_data)  # Stack the data
labels = np.array(copd_labels + non_copd_labels)  # Stack the labels

# Convert to TensorFlow tensors
data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)
labels_tensor = tf.convert_to_tensor(labels, dtype=tf.int32)

# Create TensorFlow dataset
dataset = tf.data.Dataset.from_tensor_slices((data_tensor, labels_tensor))

# Verify the dataset
for audio, label in dataset.take(2):
    print("Audio shape:", audio.shape)
    print("Label:", label.numpy())

print("Contents of NOT_COPD directory:")
try:
    print(os.listdir('/content/drive/MyDrive/training_set/NOT_COPD/'))
except Exception as e:
    print(f"Error listing directory: {e}")

# Create datasets containing the .wav files in each directory
COPD_dataset = tf.data.Dataset.list_files(COPD_files)  # Load all .wav files in COPD folder
NOT_COPD_dataset = tf.data.Dataset.list_files(NOT_COPD_files)  # Load all .wav files in Not COPD folder

# Optional: Shuffle and batch the dataset if necessary
COPD_dataset = COPD_dataset.shuffle(buffer_size=262).batch(32)
NOT_COPD_dataset = NOT_COPD_dataset.shuffle(buffer_size=262).batch(32)

# Preview the first few files in each dataset
for file in COPD_dataset.take(1):  # Preview one batch
    print(f"COPD file path: {file.numpy()}")

for file in NOT_COPD_dataset.take(1):  # Preview one batch
    print(f"Not COPD file path: {file.numpy()}")

# List files in each folder (COPD and Not COPD)
pos = tf.data.Dataset.list_files('/content/drive/MyDrive/training_set/COPD/*.wav')
neg = tf.data.Dataset.list_files('/content/drive/MyDrive/training_set/NOT_COPD/*.wav')

# Ensure the datasets are not empty
print(f"Files in pos: {len(list(pos))}")  # Should print the number of COPD files
print(f"Files in neg: {len(list(neg))}")  # Should print the number of NOT_COPD files

# Create labels: 1 for positive (COPD), 0 for negative (NOT_COPD)
pos_labels = tf.data.Dataset.from_tensor_slices(tf.ones(len(list(pos))))  # Positive labels
neg_labels = tf.data.Dataset.from_tensor_slices(tf.zeros(len(list(neg))))  # Negative labels

# Zip datasets with labels
COPD = tf.data.Dataset.zip((pos, pos_labels))  # Positive dataset with labels (1)
NOT_COPD = tf.data.Dataset.zip((neg, neg_labels))  # Negative dataset with labels (0)

# Concatenate the datasets
data = COPD.concatenate(NOT_COPD)  # Combines both positive and negative datasets

# Optional: Shuffle and batch the dataset if necessary
data = data.shuffle(buffer_size=262).batch(32)

# Check the result
for element in data.take(1):
    print(element)  # Print a batch to check the structure of the dataset

def preprocess(file_path, label):
    file_path = file_path.numpy().decode('utf-8')

    # Load and pad audio
    audio = load_and_pad_audio(file_path)

    # Convert to tensor and ensure correct shape
    audio = tf.convert_to_tensor(audio, dtype=tf.float32)
    audio = tf.expand_dims(audio, axis=-1)  # Add channel dimension

    # Ensure shapes are set
    audio.set_shape([80000, 1])

    # Convert label
    label = tf.cast(label, tf.int32)

    return audio, label

# 2. Wrap preprocessing function
def tf_preprocess(file_path, label):
    audio, label = tf.py_function(
        preprocess,
        [file_path, label],
        [tf.float32, tf.int32]
    )
    # Set shapes explicitly
    audio.set_shape([80000, 1])
    label.set_shape([])
    return audio, label

# Create balanced train/validation split
def create_balanced_splits(copd_files, not_copd_files, val_split=0.2):
    # Shuffle both sets of files
    np.random.shuffle(copd_files)
    np.random.shuffle(not_copd_files)

    # Calculate split points
    copd_split = int(len(copd_files) * (1 - val_split))
    not_copd_split = int(len(not_copd_files) * (1 - val_split))

    # Split the data
    train_copd = copd_files[:copd_split]
    val_copd = copd_files[copd_split:]
    train_not_copd = not_copd_files[:not_copd_split]
    val_not_copd = not_copd_files[not_copd_split:]

    # Combine for training and validation
    train_files = np.concatenate([train_copd, train_not_copd])
    train_labels = np.concatenate([np.ones(len(train_copd)), np.zeros(len(train_not_copd))])
    val_files = np.concatenate([val_copd, val_not_copd])
    val_labels = np.concatenate([np.ones(len(val_copd)), np.zeros(len(val_not_copd))])

    return train_files, train_labels, val_files, val_labels

# Create balanced datasets
train_files, train_labels, val_files, val_labels = create_balanced_splits(
    np.array(COPD_files),
    np.array(NOT_COPD_files)
)  # Added closing parenthesis here

# Create TensorFlow datasets
train_data = tf.data.Dataset.from_tensor_slices((train_files, train_labels))
train_data = train_data.map(tf_preprocess)  # Changed from preprocess to tf_preprocess
train_data = train_data.cache()
train_data = train_data.shuffle(buffer_size=len(train_files))
train_data = train_data.batch(32)
train_data = train_data.prefetch(tf.data.AUTOTUNE)

val_data = tf.data.Dataset.from_tensor_slices((val_files, val_labels))
val_data = val_data.map(tf_preprocess)  # Changed from preprocess to tf_preprocess
val_data = val_data.batch(32)
val_data = val_data.prefetch(tf.data.AUTOTUNE)


# Print the distribution to verify
print("\nData Distribution:")
print(f"Training - COPD: {sum(train_labels == 1)}, NOT COPD: {sum(train_labels == 0)}")
print(f"Validation - COPD: {sum(val_labels == 1)}, NOT COPD: {sum(val_labels == 0)}")

# 3. Create the dataset with proper preprocessing
all_files = np.array(COPD_files + NOT_COPD_files)
all_labels = np.array(copd_labels + non_copd_labels, dtype=np.int32)

# Create dataset and apply preprocessing
data = tf.data.Dataset.from_tensor_slices((all_files, all_labels))
data = data.map(tf_preprocess)
data = data.cache()
data = data.shuffle(buffer_size=262)
data = data.batch(32)
data = data.prefetch(tf.data.AUTOTUNE)

# 4. Verify the shapes
for audio, label in data.take(1):
    print("Audio batch shape:", audio.shape)
    print("Label batch shape:", label.shape)

# Get the first batch of data from your dataset
sample_data = next(iter(data))  # Returns a tuple of (audio_batch, label_batch)
sample_audio = sample_data[0][0]  # Gets the first audio sample from the batch
sample_label = sample_data[1][0]  # Gets the corresponding label (0 for NOT_COPD, 1 for COPD)

# Create a plot
plt.figure(figsize=(15, 5))  # Sets the size of the plot (width=15, height=5 inches)
plt.plot(sample_audio)  # Plots the audio waveform

# Add labels and title
plt.title(f"Raw Audio Waveform (Label: {'COPD' if sample_label == 1 else 'NOT COPD'})")  # Shows if it's COPD or NOT_COPD
plt.xlabel("Time (samples)")  # X-axis label
plt.ylabel("Amplitude")  # Y-axis label
plt.grid(True)  # Adds a grid to the plot
plt.show()  # Displays the plot

# Print the shape of the audio data
print("Audio shape:", sample_audio.shape)  # Should show (80000, 1) for 5 seconds of audio

# Import matplotlib if not already imported
from matplotlib import pyplot as plt

# Get a sample from the dataset
sample_data = next(iter(data))  # Get the first batch
sample_audio = sample_data[0][0].numpy()  # Get first audio from first batch and convert to numpy

# Create the waveform plot
plt.figure(figsize=(15, 5))
plt.plot(sample_audio)
plt.title("Audio Waveform")
plt.xlabel("Time (samples)")
plt.ylabel("Amplitude")
plt.grid(True)
plt.show()

# Print the shape to verify
print("Audio shape:", sample_audio.shape)

# Plot multiple examples from the batch
plt.figure(figsize=(15, 10))
for i in range(min(4, len(sample_data[0]))):
    plt.subplot(4, 1, i+1)
    plt.plot(sample_data[0][i].numpy())
    plt.title(f"Audio Sample {i+1} (Label: {sample_data[1][i].numpy()})")
    plt.xlabel("Time (samples)")
    plt.ylabel("Amplitude")
    plt.grid(True)
plt.tight_layout()
plt.show()

# Print some statistics
print("\nAudio Statistics:")
print("Min value:", np.min(sample_audio))
print("Max value:", np.max(sample_audio))
print("Mean value:", np.mean(sample_audio))

"""

1. First plot: A single audio waveform in detail

2. Second figure: Four subplots showing different samples from the same batch
"""

print("COPD Data:", copd_data)
print("Non-COPD Data:", non_copd_data)

# Assuming 'audio' is a 1D array of shape (80000,)
audio = tf.expand_dims(audio, axis=-1)  # Reshape to (80000, 1) for Conv1D or (80000, 1, 1) for Conv2D

"""# MODEL HERE"""

# Define the model
# Import required layers and models from TensorFlow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, GlobalAveragePooling1D

model = Sequential([
    Conv1D(16, 3, activation='relu', input_shape=(80000, 1)),
    MaxPooling1D(pool_size=8),
    Conv1D(32, 3, activation='relu'),
    MaxPooling1D(pool_size=8),
    Conv1D(64, 3, activation='relu'),
    GlobalAveragePooling1D(),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile with correct metric names
model.compile(
    optimizer='Adam',
    loss='binary_crossentropy',
    metrics=[
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.Recall(name='recall')
    ]
)

# Print model summary
print("\nModel Architecture:")
model.summary()

"""This time, instead of using accuracy, we only use precision and recall metrics. At first, there was an issue with the history printing (showing error as accuracy).

Another problem at the beginning was the filepath. The file extension for saving the Keras model changed, so we needed to update the ModelCheckpoint filepath. The only change is the file extension from .h5 to .keras.
"""

# Train the model
try:
    history = model.fit(
        train_data,
        epochs=10,
        verbose=1,
        validation_data=val_data,
        callbacks=[
            tf.keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=3,
                min_delta=0.01,
                restore_best_weights=True,
                verbose=1
            ),
            tf.keras.callbacks.ModelCheckpoint(
                'best_model.keras',
                monitor='val_loss',
                save_best_only=True,
                verbose=1
            )
        ]
    )

    # Print final metrics
    print("\nTraining History:")
    for epoch in range(len(history.history['loss'])):
        print(f"Epoch {epoch + 1}")
        print(f"Loss: {history.history['loss'][epoch]:.4f}")
        print(f"Precision: {history.history['precision'][epoch]:.4f}")
        print(f"Recall: {history.history['recall'][epoch]:.4f}")
        print(f"Val Loss: {history.history['val_loss'][epoch]:.4f}")
        print(f"Val Precision: {history.history['val_precision'][epoch]:.4f}")
        print(f"Val Recall: {history.history['val_recall'][epoch]:.4f}")
        print("-" * 30)

except Exception as e:
    print(f"Training error: {str(e)}")

"""##**NOW TESTING SET**

This code will
1. make predictions on validation data
2. show actual vs. predicted labels
3. show model's confidence in each prediction
4. provide details on precision, recall, F-1 score, and support
5. show confusion matrix to understand 1) how well the model performs on new data, 2) what kind of errors it is making, and 3) how confident it is in its prediciotns
"""

# Collect predictions for ALL validation data
all_labels = []
all_predictions = []
all_confidences = []

# Get predictions batch by batch
for batch_audio, batch_labels in val_data:
    predictions = model.predict(batch_audio, verbose=0)
    all_labels.extend(batch_labels.numpy())
    all_predictions.extend((predictions > 0.5).astype(int))
    all_confidences.extend(predictions)

# Convert to numpy arrays
all_labels = np.array(all_labels)
all_predictions = np.array(all_predictions)
all_confidences = np.array(all_confidences)

# Print distribution of actual labels
print("\nDistribution of Actual Labels in Validation:")
print("COPD cases:", sum(all_labels == 1))
print("NOT COPD cases:", sum(all_labels == 0))

# Print results for both classes
print("\nPrediction Results:")

# Show COPD cases
print("\nCOPD Cases:")
copd_indices = np.where(all_labels == 1)[0]
for i in copd_indices[:10]:  # Show first 10 COPD cases
    print(f"Sample {i+1}:")
    print(f"True Label: COPD")
    print(f"Predicted: {'COPD' if all_predictions[i] == 1 else 'NOT COPD'}")
    print(f"Confidence: {all_confidences[i][0]:.4f}")
    print("-" * 30)

# Show NOT COPD cases
print("\nNOT COPD Cases:")
not_copd_indices = np.where(all_labels == 0)[0]
for i in not_copd_indices[:10]:  # Show first 10 NOT COPD cases
    print(f"Sample {i+1}:")
    print(f"True Label: NOT COPD")
    print(f"Predicted: {'COPD' if all_predictions[i] == 1 else 'NOT COPD'}")
    print(f"Confidence: {all_confidences[i][0]:.4f}")
    print("-" * 30)

# Calculate and print metrics
from sklearn.metrics import classification_report, confusion_matrix
print("\nClassification Report:")
print(classification_report(all_labels, all_predictions))

print("\nConfusion Matrix:")
print(confusion_matrix(all_labels, all_predictions))

"""--> concerns:
1. imbalanced validation data (all 32 samples are NOT COPD)
2. confused matrix -> 30 correct NOT COPD predictions but no COPD cases to predict
3. low confidence scores (all between 0.0006 to 0.0628)

This is to see the distribution of COPD vs. NOT COPD cases.
-> to see if we need to balance the training data and collect more COPD samples.

We found out that there is AN IMBALANCED SET. Hence, I had to go back before the machine learning to RE-TRAIN the data.
"""

# Save the trained model
model.save('copd_detection_model.keras')

"""now that i've saved my model, I need to test it on a new batch of data.

"""

def predict_new_audio(file_path, threshold=0.5):
    try:
        print(f"\nProcessing file: {file_path}")

        # Step 1: Load audio using librosa with fixed sample rate
        audio, _ = librosa.load(file_path, sr=16000)

        # Step 2: Pad or truncate to fixed length (80000 samples)
        if len(audio) > 80000:
            audio = audio[:80000]
        else:
            audio = np.pad(audio, (0, 80000 - len(audio)), 'constant')

        # Step 3: Convert to tensor with correct shape
        audio_tensor = tf.convert_to_tensor(audio, dtype=tf.float32)
        audio_tensor = tf.reshape(audio_tensor, (1, 80000, 1))

        print("Audio shape:", audio_tensor.shape)

        # Step 4: Make prediction
        prediction = model.predict(audio_tensor, verbose=0)
        prediction_value = float(prediction[0][0])

        # Step 5: Apply threshold and return results
        is_copd = prediction_value >= threshold

        print(f"Prediction score: {prediction_value:.4f}")
        print(f"Classification: {'COPD' if is_copd else 'NOT COPD'}")

        return {
            'score': prediction_value,
            'is_copd': bool(is_copd),
            'classification': 'COPD' if is_copd else 'NOT COPD'
        }

    except Exception as e:
        print(f"Error processing audio: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

# Test the function
test_folder = '/content/drive/MyDrive/testing_set'
copd_folder = os.path.join(test_folder, 'COPD')

# Get first 5 test files
test_files = [f for f in os.listdir(copd_folder)
              if f.endswith('.wav') and 'part 1' in f][:5]

# Test each file
for file in test_files:
    print(f"\nTesting file: {file}")
    file_path = os.path.join(copd_folder, file)
    result = predict_new_audio(file_path)
    if result:
        print(f"Result: {result}")

# Test with a lower threshold since many COPD cases seem to be in the 0.54-0.61 range
threshold = 0.45  # Try a lower threshold to catch more COPD cases

test_files = [
    '1-1 part 1.wav',
    '1-2 part 1.wav',
    '1-3 part 1.wav',
    '1-4 part 1.wav',
    '1-5 part 1.wav',
]

print("Testing with threshold:", threshold)
for filename in test_files:
    test_file = os.path.join('/content/drive/MyDrive/testing_set/COPD', filename)
    print(f"\nTesting file: {filename}")
    predict_new_audio(test_file, threshold)

"""Now, I need to save my work."""

# 1. Save your trained model with the new name
model_save_path = '/content/drive/MyDrive/smart_diagnosis_model.keras'
model.save(model_save_path)
print(f"Model saved to: {model_save_path}")

# 2. Create prediction script with updated name
prediction_code = '''
import tensorflow as tf
import librosa
import numpy as np
import os

def load_and_pad_audio(file_path):
    audio, _ = librosa.load(file_path, sr=16000)
    fixed_length = 80000
    if len(audio) < fixed_length:
        audio = np.pad(audio, (0, fixed_length - len(audio)), 'constant')
    else:
        audio = audio[:fixed_length]
    return audio

def smart_diagnosis(audio_path, threshold=0.45):
    try:
        model = tf.keras.models.load_model('/content/drive/MyDrive/smart_diagnosis_model.keras')

        audio = load_and_pad_audio(audio_path)
        audio = tf.convert_to_tensor(audio, dtype=tf.float32)
        audio = tf.expand_dims(audio, axis=-1)
        audio = tf.expand_dims(audio, axis=0)

        prediction = model.predict(audio, verbose=0)
        confidence = prediction[0][0]

        return {
            "filename": os.path.basename(audio_path),
            "diagnosis": "COPD" if confidence > threshold else "NOT COPD",
            "confidence": float(confidence),
            "threshold_used": threshold
        }
    except Exception as e:
        return {
            "error": str(e),
            "filename": os.path.basename(audio_path)
        }
'''

# Save the prediction script
script_path = '/content/drive/MyDrive/smart_diagnosis.py'
with open(script_path, 'w') as f:
    f.write(prediction_code)
print("Smart Diagnosis script saved to:", script_path)

# Test the function directly
def smart_diagnosis(audio_path, threshold=0.45):
    try:
        audio = load_and_pad_audio(audio_path)
        audio = tf.convert_to_tensor(audio, dtype=tf.float32)
        audio = tf.expand_dims(audio, axis=-1)
        audio = tf.expand_dims(audio, axis=0)

        prediction = model.predict(audio, verbose=0)
        confidence = prediction[0][0]

        return {
            "filename": os.path.basename(audio_path),
            "diagnosis": "COPD" if confidence > threshold else "NOT COPD",
            "confidence": float(confidence),
            "threshold_used": threshold
        }
    except Exception as e:
        return {
            "error": str(e),
            "filename": os.path.basename(audio_path)
        }

# Test with a file
print("\nTesting diagnosis function...")
test_file = '/content/drive/MyDrive/testing_set/COPD/1-1 part 1.wav'
result = smart_diagnosis(test_file)
print("\nTest diagnosis result:")
print(result)

"""Now, we need to connect it to the app."""

# Create the Streamlit app file
with open('app.py', 'w') as f:
    f.write('''
import streamlit as st

# Load the model
@st.cache_resource  # This will cache the model loading
def load_model():
    return tf.keras.models.load_model('smart_diagnosis_model.keras')

model = load_model()

def smart_diagnosis(audio_file):
    try:
        # Process the audio file (your existing code)
        audio, sr = librosa.load(audio_file, sr=16000)
        # Add your preprocessing steps here

        # Make prediction
        prediction = model.predict(audio)
        confidence = float(prediction[0][0])

        return {
            "diagnosis": "COPD" if confidence > 0.5 else "NOT COPD",
            "confidence": confidence * 100  # Convert to percentage
        }
    except Exception as e:
        return {"error": str(e)}

# Create the Streamlit interface
st.title("COPD Detection System")
st.write("Upload a breathing sound recording to check for COPD indicators.")

# File uploader
audio_file = st.file_uploader("Upload Audio File", type=['wav'])

if audio_file is not None:
    st.audio(audio_file)

    if st.button("Analyze Audio"):
        with st.spinner("Analyzing..."):
            # Save temporarily
            temp_path = "temp_audio.wav"
            with open(temp_path, "wb") as f:
                f.write(audio_file.getbuffer())

            # Get prediction
            result = smart_diagnosis(temp_path)

            # Clean up
            os.remove(temp_path)

            # Show results
            if "error" in result:
                st.error(f"Error: {result['error']}")
            else:
                st.subheader("Results:")
                st.write(f"Diagnosis: {result['diagnosis']}")
                st.write(f"Confidence: {result['confidence']:.2f}%")

                # Add a progress bar for confidence
                st.progress(result['confidence'] / 100)
    ''')

# Now let's test the app locally
# Replace !streamlit run app.py & npx localtunnel --port 8501 with Python equivalent
# Note: This would typically be run from the command line, not within Python
# If you need to run it from Python, you can use:
try:
    # Start streamlit
    streamlit_process = subprocess.Popen(["streamlit", "run", "app.py"])
    # Start localtunnel
    tunnel_process = subprocess.Popen(["npx", "localtunnel", "--port", "8501"])
    
    # Keep the processes running
    streamlit_process.wait()
    tunnel_process.wait()
except Exception as e:
    print(f"Error starting servers: {e}")

with open('requirements.txt', 'w') as f:
    f.write('''
streamlit
tensorflow
numpy
librosa
''')
